{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the WebScraper using Selenium to gather Geeks Who Drink(GWD) data in Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time as time\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_driver = \"../chromedriver_win32/chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the webdriver for viz\n",
    "browser = webdriver.Chrome(executable_path=path_to_driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.geekswhodrink.com/schedule/TX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the URL\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this to wait for the site to load.\n",
    "time.sleep(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the data to be collected from the sites.\n",
    "data ={}\n",
    "dow = []\n",
    "venue = []\n",
    "city = []\n",
    "time = []\n",
    "urls = []\n",
    "date = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [day.text for day in browser.find_elements_by_tag_name(\"h3\")[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "1 Sunday\n",
      "2 Monday\n",
      "3 Tuesday\n",
      "4 Wednesday\n",
      "5 Thursday\n",
      "6 Saturday\n"
     ]
    }
   ],
   "source": [
    "#Using 0 as a beginning date because div 0 doesn't exist. Use it as placeholder to interate through the next DOW\n",
    "for l in range(len(days)):\n",
    "    print(l,days[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:17<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "source": [
    "#finds the urls between each h3 header\n",
    "##tqdm is used for the statusbar\n",
    "for stuff in tqdm(range(len(days))):\n",
    "    for i in browser.find_elements_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/div['+str(stuff)+']'):\n",
    "        for links in i.find_elements_by_tag_name(\"a\"):\n",
    "            dow.append(days[stuff])\n",
    "            urls.append(links.get_attribute(\"href\"))\n",
    "            venue.append(links.text)\n",
    "        for c in i.find_elements_by_tag_name(\"i\"):\n",
    "            city.append(c.text)\n",
    "        for t in i.find_elements_by_tag_name(\"time\"):\n",
    "            if (t.text[0]).isnumeric() == True:\n",
    "                time.append(t.text)\n",
    "            else: \n",
    "                date.append(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 177, 177, 177, 177)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks to ensure that data is the same length\n",
    "len(city),len(venue),len(dow),len(time),len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[city,venue,dow,time,urls]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['city','venue','dow','time','urls']\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuesday      54\n",
       "Wednesday    50\n",
       "Thursday     32\n",
       "Monday       26\n",
       "Sunday        9\n",
       "Saturday      6\n",
       "Name: dow, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dow'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking all of the Austin locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin  = df[df['city'] == '(Austin)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the data as a whole\n",
    "## use a datestamp to ensure that there isn't data overwritten unless it's on the same day.\n",
    "df.to_csv('./data/'+str(datetime.today())[:10]+'_GWD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using this to match the indexes for Tableau\n",
    "austin = austin.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin.to_csv('./data/'+str(datetime.today())[:10]+'_GWD_Austin.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
